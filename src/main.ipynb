{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6762474c",
   "metadata": {},
   "source": [
    "# ML Project - Tweet Success Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8757a9c",
   "metadata": {},
   "source": [
    "This model uses a processed dataset that was previously treated and analysis in an EDA project. Raw dataset has been extracted from Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa35730",
   "metadata": {},
   "source": [
    "The goal of this work is to create a classifying model to determine the degree of success (Low, Medium or High) of a tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce4cca",
   "metadata": {},
   "source": [
    "Steps will be as followed:\n",
    "\n",
    "1. Load dataset <br />\n",
    "2. Define target value\n",
    "3. Features Transformation <br />\n",
    "&nbsp;&nbsp;&nbsp; 3.1 Change of formats and slicing of ds <br />\n",
    "&nbsp;&nbsp;&nbsp; 3.2 Create new features <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.1 Flag for exclamation mark in tweet <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.2 Feature containing polarity of tweet <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.2.1 Transformation of tweet for lexicon model <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.2.2 Lexicon model <br />\n",
    "4. Pre-processing pipelines <br />\n",
    "5. Models training  <br />\n",
    "6. Final model selection\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5160514",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddaf74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries and other main functions\n",
    "import joblib\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from utils.functions import transformations, features, text_cleaning, lexicon, model\n",
    "from utils.datos import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fceb4e",
   "metadata": {},
   "source": [
    "## Loading data from EDA project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca93c4",
   "metadata": {},
   "source": [
    "Data has been previously cleaned and explored during EDA project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5da82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78585f47",
   "metadata": {},
   "source": [
    "## Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24fe837",
   "metadata": {},
   "source": [
    "New variable to contain the target value, which is defined as a category variable that identifies the degree of success of the tweet (0 for Low, 1 for Medium and 2 for High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8a1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['categoria_tr']=tweets['Total_reac'].apply(transformations.target_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc442f1d",
   "metadata": {},
   "source": [
    "## Features Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b49da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function converts all column names to lowercase \n",
    "tweets = transformations.lower(tweets)\n",
    "\n",
    "# add column that checks for exclamation mark in tweets\n",
    "tweets['exclama'] = tweets.tweet.apply(features.exclamation)\n",
    "\n",
    "# add column that detects tweet language, and keep only spanish tweets\n",
    "tweets['lang'] = tweets.tweet.apply(features.lang_detect)\n",
    "tweets_es = tweets[tweets.lang == 'es']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e90e10",
   "metadata": {},
   "source": [
    "### Polarity feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d0de7f",
   "metadata": {},
   "source": [
    "**Tweet cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca410fc2",
   "metadata": {},
   "source": [
    "To get the polarity of the tweet we first need to clean it: we will remove hashtags, web mentions, urls, punction sings, stopwords and other symbols.\n",
    "Given the nature of the tweets it is not neccesary to correct grammar nor to remove emoticons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179bccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove hashtags/otros\n",
    "tweets_es.tweet = tweets_es.tweet.apply(text_cleaning.hashtags)\n",
    "\n",
    "#remove web mention\n",
    "tweets_es.tweet = tweets_es.tweet.apply(text_cleaning.webs)\n",
    "\n",
    "#remove punctuation marks\n",
    "tweets_es.tweet = tweets_es.tweet.apply(text_cleaning.punctuation_marks)\n",
    "\n",
    "#remove html\n",
    "tweets_es.tweet = tweets_es.tweet.apply(text_cleaning.html)\n",
    "\n",
    "#remove stopwords\n",
    "tweets_es.tweet = tweets_es.tweet.apply(text_cleaning.remove_stopwords)\n",
    "\n",
    "#remove others\n",
    "tweets_es.tweet = tweets_es.tweet.apply(text_cleaning.remove_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039273d",
   "metadata": {},
   "source": [
    "**Lexicon model to define polarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9b3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to define the polarity of each tweet first we lemmatize the tweet text, and then calculate the polatiry based on a score\n",
    "tweets_es[\"polarity\"] = tweets_es.tweet.apply(lexicon.lemma_doc).apply(lexicon.score_lexicon_lemmatized, path = path_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb48e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save processed dataset to use in classficication model\n",
    "tweets_es.to_csv(\"data/processed_files/tweets_final.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb35cb",
   "metadata": {},
   "source": [
    "### Define features of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47db52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read final dataframe to be used for classification model\n",
    "df_model = pd.read_csv(path_final_data)\n",
    "\n",
    "#Features selection for classification model\n",
    "df_features = df_model.drop(columns=['tweet', 'created_at','retweets', 'likes', 'id', 'entities', 'engage_rate', 'name', 'lang', 'hashtag_text', 'year','total_reac','categoria_tr'])\n",
    "\n",
    "#Train & Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_model.categoria_tr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6da9b81",
   "metadata": {},
   "source": [
    "## Pre-processing pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a8675",
   "metadata": {},
   "source": [
    "Pre-processing pipelines defined to scale numerical variables and labeling categorical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b73a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordinal encoding for ordinal features\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"OrdinalEncoder\", OrdinalEncoder()) #OE fot categorical ones\n",
    "    ])\n",
    "\n",
    "#Scaling for ordinal features\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"SScaler\", StandardScaler()) #Standarization for numerical values\n",
    "    ])\n",
    "\n",
    "#Pre-processing pipeline that combines scaling and labeling. This pipeline will later be used when training model\n",
    "preprocessing = ColumnTransformer(\n",
    "    [(\"Impute_Numeric\", num_pipeline, [\"followers\",\"month\", 'week_day', 'hour', 'tweet_len']),\n",
    "     (\"Process_Categorical\", cat_pipeline, [\"user\",\"polarity\"]),\n",
    "    ], remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb4bb4f",
   "metadata": {},
   "source": [
    "## Classification models training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40e2a2",
   "metadata": {},
   "source": [
    "### Classification model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9462f8d3",
   "metadata": {},
   "source": [
    "Four different models will be tested using GridSearchCV to optimize parameters based on accuracy metric.\n",
    "\n",
    "Four models are: LightGBM, XGBoost, RandomForest and K-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3baca9",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85c2d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "Best accuracy for model is 0.59\n"
     ]
    }
   ],
   "source": [
    "classifier = LGBMClassifier() #class of model to be used\n",
    "scoring = 'accuracy' #metric to be used in GridSearch\n",
    "parameters = { #parameters to be used in GridSearch\n",
    "    'model__min_data_in_leaf': (100,200,300),\n",
    "    'model__max_depth': (2,4,6,8,10)\n",
    "}\n",
    "\n",
    "#Function that trains a model based on the inputs provided. This function returns the model that has been trained in the first position of the array,\n",
    "#and the score that the model obtained in the second position of the array. For more info refer to help(model.gridsearch_score)\n",
    "clas_model_lgbm = model.gridsearch_score(preprocessing, classifier, parameters, scoring, X_train, y_train)\n",
    "print(clas_model_lgbm[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73867a",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba6e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for model is 0.58\n"
     ]
    }
   ],
   "source": [
    "classifier = XGBClassifier() #class of model to be used\n",
    "scoring = 'accuracy' #metric to be used in GridSearch\n",
    "parameters = { #parameters to be used in GridSearch\n",
    "    'model__learning_rate': [0.05, 0.1, 0.2, 0.4],\n",
    "    'model__max_depth': (2,4,6,8,10),\n",
    "    \"model__n_estimators\": [50, 100, 150, 200, 300, 500],\n",
    "    'model__random_state': [42]\n",
    "}\n",
    "\n",
    "#Function that trains a model based on the inputs provided. This function returns the model that has been trained in the first position of the array,\n",
    "#and the score that the model obtained in the second position of the array. For more info refer to help(model.gridsearch_score)\n",
    "clas_model_xgbc = model.gridsearch_score(preprocessing, classifier, parameters, scoring, X_train, y_train)\n",
    "print(clas_model_xgbc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26d84a",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a45371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for model is 0.59\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier() #class of model to be used\n",
    "scoring = 'accuracy' #metric to be used in GridSearch\n",
    "parameters = { #parameters to be used in GridSearch\n",
    "    'model__max_depth': (2,4,6,8,10),\n",
    "    'model__max_features': (1,2,3,4,5,6,8,10),\n",
    "    \"model__n_estimators\": [50, 100, 150], \n",
    "}\n",
    "\n",
    "#Function that trains a model based on the inputs provided. This function returns the model that has been trained in the first position of the array,\n",
    "#and the score that the model obtained in the second position of the array. For more info refer to help(model.gridsearch_score)\n",
    "clas_model_rfc = model.gridsearch_score(preprocessing, classifier, parameters, scoring, X_train, y_train)\n",
    "print(clas_model_rfc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae55da0",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "688c4b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for model is 0.55\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier() #class of model to be used\n",
    "scoring = 'accuracy' #metric to be used in GridSearch\n",
    "parameters = { #parameters to be used in GridSearch\n",
    "    'model__n_neighbors': (6,8,10,100,150)\n",
    "}\n",
    "\n",
    "#Function that trains a model based on the inputs provided. This function returns the model that has been trained in the first position of the array,\n",
    "#and the score that the model obtained in the second position of the array. For more info refer to help(model.gridsearch_score)\n",
    "clas_model_knn = model.gridsearch_score(preprocessing, classifier, parameters, scoring, X_train, y_train)\n",
    "print(clas_model_knn[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d4067",
   "metadata": {},
   "source": [
    "## Final model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6774a721",
   "metadata": {},
   "source": [
    "The two best performing models (LightGBM and Random Forest) will be analized against Test data in order to select final model. This analysis will be performed using a classification report & confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f2e83",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7739061b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58       416\n",
      "           1       0.53      0.49      0.51       529\n",
      "           2       0.65      0.69      0.67       492\n",
      "\n",
      "    accuracy                           0.59      1437\n",
      "   macro avg       0.58      0.59      0.58      1437\n",
      "weighted avg       0.58      0.59      0.58      1437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict with LightGBM model and print confusion matrix\n",
    "y_pred_lgbm = clas_model_lgbm[0].predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dfc0d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[242, 132,  42],\n",
       "       [130, 258, 141],\n",
       "       [ 53,  98, 341]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create confusion matrix and plot it with seaborn heatmap\n",
    "c_matrix = confusion_matrix(y_test, y_pred_lgbm)\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ca573",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a5849ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.58      0.59       416\n",
      "           1       0.55      0.50      0.53       529\n",
      "           2       0.66      0.74      0.70       492\n",
      "\n",
      "    accuracy                           0.61      1437\n",
      "   macro avg       0.60      0.61      0.60      1437\n",
      "weighted avg       0.60      0.61      0.60      1437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict with Random Forest and print confusion matrix\n",
    "y_pred_rfc = clas_model_rfc[0].predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01c72a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[241, 128,  47],\n",
       "       [124, 267, 138],\n",
       "       [ 41,  89, 362]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create confusion matrix and plot it with seaborn heatmap\n",
    "c_matrix = confusion_matrix(y_test, y_pred_rfc)\n",
    "c_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a63ed00f",
   "metadata": {},
   "source": [
    "## Production Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef664205",
   "metadata": {},
   "source": [
    "The best performing model proved to be RandomForest. This model will be trained with the whole dataset and then saved for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49404ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final model to be trained with whole dataset\n",
    "classifier = RandomForestClassifier() #class of model to be used\n",
    "scoring = 'accuracy' #metric to be used in GridSearch\n",
    "parameters = { #parameters to be used in GridSearch\n",
    "    'model__max_depth': (2,4,6,8,10),\n",
    "    'model__max_features': (1,2,3,4,5,6,8,10),\n",
    "    \"model__n_estimators\": [50, 100, 150], \n",
    "}\n",
    "\n",
    "#Function that trains a model based on the inputs provided. This function returns the model that has been trained in the first position of the array,\n",
    "#and the score that the model obtained in the second position of the array. For more info refer to help(model.gridsearch_score)\n",
    "final_model = model.gridsearch_score(preprocessing, classifier, parameters, scoring, df_features, df_model.categoria_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4038f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/processed_files/tweet_success_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(final_model[0], \"data/processed_files/tweet_success_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
